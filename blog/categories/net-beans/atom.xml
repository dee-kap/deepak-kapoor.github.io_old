<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Net Beans | Deepak Kapoor]]></title>
  <link href="http://www.deepakkapoor.net/blog/categories/net-beans/atom.xml" rel="self"/>
  <link href="http://www.deepakkapoor.net/"/>
  <updated>2013-12-05T22:37:14+11:00</updated>
  <id>http://www.deepakkapoor.net/</id>
  <author>
    <name><![CDATA[Deepak Kapoor]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Yet Another Hadoop Word Count Tutorial]]></title>
    <link href="http://www.deepakkapoor.net/2012/07/10/yet-another-hadoop-word-count-tutorial/"/>
    <updated>2012-07-10T00:00:00+10:00</updated>
    <id>http://www.deepakkapoor.net/2012/07/10/yet-another-hadoop-word-count-tutorial</id>
    <content type="html"><![CDATA[<p>Here is another Word Count count Hadoop tutorial. Why? You ask. It is a learning exercise for me. I am writing it out so that I can refer to it in future. Also, rather than just copying the example already available with Hadoop installation, I will try to fix some shortcomings of the word count program. Before I do that, let’s just write a stock-standard one. </p>


<p> <p>For this walkthrough if you want to call it that, I have Hadoop running on a single node setup on Ubuntu 11.10. My preferred IDE is Netbeans.</p> <p>Here it goes.</p> <h3>Create a project</h3> <p>First of all create a Java project in Netbeans. Call it HadoopWordCountTutorial. I also like to use proper package names so my class HadoopWordCountTutorial is in package com.thereforesystems.hadoop.</p> <p><img style="background-image: none; border-right-width: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="https://googledrive.com/host/0B6PDO8HPEQZNZWpTRms0ZWtlaUU/uploads/2012/07/image.png" width="640" height="398"></p> <p>&nbsp;</p> <h3>Add Libraries</h3> <p>Next thing we need to do is add some libraries. Here is a list of libraries required to compile our Hadoop project.</p> <p><img style="background-image: none; border-right-width: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top-width: 0px; border-bottom-width: 0px; border-left-width: 0px; padding-top: 0px" title="image" border="0" alt="image" src="https://googledrive.com/host/0B6PDO8HPEQZNZWpTRms0ZWtlaUU/uploads/2012/07/image1.png" width="459" height="261"></p> <p>These jars can be found in your Hadoop folders. An easy way to find where things are is by using locate command. For example to locate hadoop-core-0.20.2-cdh3u4.jar execute the command in terminal.</p> <p><font color="#0000ff">locate hadoop-core-0.20.2-cdh3u4.jar</font></p> <p>On my machine the file is located in </p> <p>/usr/lib/hadoop-0.20/</p> <p>Once we have added required libraries, we are all set to write some code. </p> <h3>Writing code</h3> <p>Hadoop is a framework which provides us plumbing to write MapReduce operations (This is such an understatement). Here is a <a href="http://code.google.com/edu/parallel/mapreduce-tutorial.html">good tutorial on MapReduce</a>. If you are not familiar with MapReduce then I suggest that you read it before continuing with this tutorial. </p> <p>There are two operations we will write. One is the mapper and the other is reducer. Our objective is to count words in a file or many files and write the results to an output location. We will start with our mapper.</p> <h3>Mapper</h3> <p>Mapper in Hadoop is implemented by extending Mapper class found in org.apache.hadoop.mapreduce. This class implements a map method in which we will write our logic. Here is the code for our class.</p></p>

<pre class="lang:java decode:true " >
public static class WordCountMapper extends Mapper<Object /* KEYIN */, 
            Text /* VALUEIN */, 
            Text /* KEYOUT */, 
            IntWritable /* VALUEOUT */> {

    private Text word = new Text();
    private final static IntWritable numberOne = new IntWritable(1);

    public void map(Object key, Text value, Context context) 
        throws IOException, InterruptedException {

        StringTokenizer tokenizer = new StringTokenizer(value.toString());
        while (tokenizer.hasMoreTokens()) {
            word.set(tokenizer.nextToken());
            context.write(word, numberOne);
             
        }
    }
}
</pre>




<p>Let’s look at the map method. The map method tokenizes the text passed in. What gets passed in is handled by Hadoop. Keep in mind that text for the entire file may not be passed in to the mapper. And this is a good thing. Imagine if the file was many gigabytes in size, Hadoop will take care of splitting the file into blocks and will spin off <em>n</em> number of mappers to handle the chunked file.</p>


<p> <h3>Reducer</h3> <p>The reducer is implemented in a class which extends Reducer. Here is the code for Reducer.</p></p>

<pre class="lang:java decode:true " >
public static class WordCountReducer extends Reducer<Text /* KEYIN */, 
            IntWritable /* VALUEIN */, 
            Text /* KEYOUT */, 
            IntWritable /* VALUEOUT */> {
        
    public void reduce(Text key, Iterable<IntWritable> values, Context context) 
        throws IOException, InterruptedException {
        
        int sum = 0;
        for(IntWritable val : values){
            sum += val.get();
        }
            
        context.write(key, new IntWritable(sum));
    }
}
</pre>




<p>The method of interest here is reduce() which receives a list of IntWritable objects for a key. In our example a key will be a word. For example the word could be “Imagine” which occurs many times in our file. After Mapper is done, Reducer will be called for key “Imagine” and values [1, 2, 1, 1]. Within our reduce method we sum the values up for each key and write it out. Writing out part is handled by the Context for us.</p>


<p> <h3>Main method</h3> <p>Main method is where it all get’s tied up. Let’s look at the main method.</p></p>

<pre class="lang:java decode:true " >
public static void main(String[] args) 
    throws IOException, InterruptedException, ClassNotFoundException {
        
    Configuration config = new Configuration();
    String[] otherArgs = new GenericOptionsParser(config, args).getRemainingArgs();
        
    Job job = new Job(config, "Word Count Tutorial");
    job.setJarByClass(HadoopWordCountTutorial.class);
    job.setMapperClass(WordCountMapper.class);
    job.setReducerClass(WordCountReducer.class);
        
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
        
    FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
    FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));
        
    System.exit(job.waitForCompletion(true) ? 0 : 1);
}
</pre>




<p>The first thing we do is create an instance of Configuration object. This returns us the default configuration for our installation.&nbsp; Next we parse arguments passed in. These arguments for the purpose of this example are input-directory and output-directory. Note that Hadoop will create output directory for us and it should not already exist.</p>


<p> <p>We then create an instance of Job object by passing in the configuration instance and a name for our job. Next three lines tell Hadoop about our Jar file, the mapper it should use and the reducer it should use for the job.</p> <p>After this we call setOutputKeyClass and setOutputValueClass on the job instance. This tells Hadoop about data types we expect it to deal with.</p> <p>Finally we set the locations for input directory and output directory. </p> <h3>Running the job</h3><p>We are all set to run this job. I executed this job by pointing it to a directory which contains only one file. This file is lyrics for Imagine by John Lennon. </p></p>

<p>On my machine I executed the job with this command.</p>


<p><font color="#0000ff">java -jar /home/deepak/NetBeansProjects/HadoopWordCountTutorial/dist/HadoopWordCountTutorial.jar /home/deepak/temp/HadoopWordCountTutorial/input /home/deepak/temp/HadoopWordCountTutorial/output</font></p>




<p>After the job is run, the output shows me how many times a particular word occured in the file. Here is partial output.</p>


<p> <p><img style="background-image: none; border-bottom: 0px; border-left: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top: 0px; border-right: 0px; padding-top: 0px" title="image" border="0" alt="image" src="https://googledrive.com/host/0B6PDO8HPEQZNZWpTRms0ZWtlaUU/uploads/2012/07/image2.png" width="134" height="460"></p> <p>What is wrong with this output? Take a look at the partial output above, you will notice that “A” has been counted as 1 and “a” is counted as 2. To resolve this issue we can tell our StringTokenizer to ignore certain characters.</p></p>

<pre class="lang:java decode:true " >
StringTokenizer tokenizer = 
    new StringTokenizer(value.toString(), " tnrf,.:;?[]'(),~!@#%^&*()_");
</pre>




<p>Also when we all word.set we can call toLowerCase method. This will make all our keys lowercase and provide expected ouput.</p>


<p></p>

<pre class="lang:java decode:true " >
word.set(tokenizer.nextToken().toLowerCase());
</pre>




<p>Here is the output after making two minor changes. We now have the count for “a” as 3. This is what we expected.</p>


<p> <p><img style="background-image: none; border-bottom: 0px; border-left: 0px; margin: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top: 0px; border-right: 0px; padding-top: 0px" title="image" border="0" alt="image" src="https://googledrive.com/host/0B6PDO8HPEQZNZWpTRms0ZWtlaUU/uploads/2012/07/image3.png" width="127" height="310"></p> <p>&nbsp;</p> <h3>Conclusion</h3> <p>This concludes the post. I hope you learned a thing or two here. These days I am spending more and more time with Hadoop and most importantly I am enjoying my time with it. Stay tuned for more ramblings as I make my way through this massive framework.</p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Axis2 Plugin for Netbeans 7.1.2]]></title>
    <link href="http://www.deepakkapoor.net/2012/05/25/axis2-plugin-for-netbeans-7-1-2/"/>
    <updated>2012-05-25T00:00:00+10:00</updated>
    <id>http://www.deepakkapoor.net/2012/05/25/axis2-plugin-for-netbeans-7-1-2</id>
    <content type="html"><![CDATA[<p>I upgraded Netbeans today and found that there is no Axis2 plugin available via Tools –&gt; Plugins. Looks like Axis2 support plugin has been discontinued in Netbeans. However the link below works and I was able to install the plugin. This post hopefully will serve as a bookmark when I’m looking for Axis2 plugin in Netbeans next time.</p>


<p> <p><a title="http://deadlock.netbeans.org/hudson/job/nbms-and-javadoc/lastStableBuild/artifact/nbbuild/nbms/updates.xml.gz" href="http://deadlock.netbeans.org/hudson/job/nbms-and-javadoc/lastStableBuild/artifact/nbbuild/nbms/updates.xml.gz"><a href="http://deadlock.netbeans.org/hudson/job/nbms-and-javadoc/lastStableBuild/artifact/nbbuild/nbms/updates.xml.gz">http://deadlock.netbeans.org/hudson/job/nbms-and-javadoc/lastStableBuild/artifact/nbbuild/nbms/updates.xml.gz</a></a></p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Add Javadoc to Netbeans]]></title>
    <link href="http://www.deepakkapoor.net/2011/01/01/add-javadoc-to-netbeans/"/>
    <updated>2011-01-01T00:00:00+11:00</updated>
    <id>http://www.deepakkapoor.net/2011/01/01/add-javadoc-to-netbeans</id>
    <content type="html"><![CDATA[<p>I installed Netbeans 6.9 on my machine and found that Javadoc is not installed. For example when invoking intellisense for a method in Calendar class I get the following message. </p>


<p><img src="https://googledrive.com/host/0B6PDO8HPEQZNZWpTRms0ZWtlaUU/uploads/2011/01/snapshot3.png" title="Javadoc" alt="Javadoc not available" /></p>


<p>Javadoc is not installed with Netbeans by default but can easily be installed. This is how it's done.</p>


<p>First download documentation from this <a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" title="Javadoc download link" target="_blank">link</a>. Get the documentation zip file and copy it to a folder. Next go to Tools --&gt; Java Platforms in Netbeans. This brings up Java Platform Manager. On this screen select the environment e.g. JDk 1.6 and then click on Javadoc tab. Browse to the zip file and click close on Java Platform Manager.</p>


<p><img src="https://googledrive.com/host/0B6PDO8HPEQZNZWpTRms0ZWtlaUU/uploads/2011/01/snapshot5copy.png" title="Netbeans-Java Platforms Manager" alt="Netbeans-Java Platforms Manager" /></p>


<p>Javadoc will now be available.</p>


<p><img src="https://googledrive.com/host/0B6PDO8HPEQZNZWpTRms0ZWtlaUU/uploads/2011/01/snapshot4.png" /></p>


<p></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Running Glassfish In Verbose Mode From NetBeans]]></title>
    <link href="http://www.deepakkapoor.net/2010/08/23/running-glassfish-in-verbose-mode-from-netbeans/"/>
    <updated>2010-08-23T00:00:00+10:00</updated>
    <id>http://www.deepakkapoor.net/2010/08/23/running-glassfish-in-verbose-mode-from-netbeans</id>
    <content type="html"><![CDATA[<p>The title of this post "Running Glassfish In Verbose Mode From NetBeans" is slightly misleading because what I am showing here is a way to view Glassfish logs within NetBeans IDE.</p>


<p>To start Glassfish in verbose mode on a command prompt or Terminal on a mac you'll use this command.</p>


<p><strong>asadmin start-domain --verbose</strong></p>


<p>This will show you a nice verbose log of Glassfish activity on the Terminal.</p>


<p><strong></strong> From NetBeans all you need to do is start Glassfish as you normally would.</p>


<p><img title="Screen shot 2010-08-23 at 5.09.05 PM.png" src="https://googledrive.com/host/0B6PDO8HPEQZNZWpTRms0ZWtlaUU/uploads/2010/08/Screen-shot-2010-08-23-at-5.09.05-PM1.png" border="0" alt="Start Glassfish" width="375" height="397" /></p>


<p>Now click on View Server Log and you'll see a log of all Glassfish activity in NetBeans IDE.</p>


<p><img style="float: left;" title="Glassfish2.png" src="https://googledrive.com/host/0B6PDO8HPEQZNZWpTRms0ZWtlaUU/uploads/2010/08/Glassfish21.png" border="0" alt="Screen shot 2010-08-23 at 5.20.17 PM.png" width="372" height="417" /></p>

]]></content>
  </entry>
  
</feed>
